[
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03944954128440368,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07172643869891572,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.03921568627450981,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07130124777183598,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03944954128440368,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07172643869891572,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.03921568627450981,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07130124777183598,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.043883792048929664,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07803725326661103,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.04379084967320263,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07754010695187163,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.04396551724137933,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07847439916405431,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.07426095820591228,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.10859843520393976,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.06198257080610024,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.09494949494949492,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.0850574712643678,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.12060008956560678,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.12055846803553218,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.1497531011292479,
        "total_reciprocal_rank": 0.22507645259938833,
        "total_hard_percision": 0.10565670712729539,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.13598449480802421,
        "total_hard_reciprocal_rank": 0.23976034858387799,
        "total_easy_percision": 0.13366174055829222,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.16185997910135833,
        "total_easy_reciprocal_rank": 0.2121647509578544
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.11294597349643222,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.12262996941896023,
        "total_reciprocal_rank": 0.13149847094801223,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07375478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0839080459770115,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02522935779816512,
        "total_recall": 0.5045871559633027,
        "total_f1_score": 0.048055919615552625,
        "total_reciprocal_rank": 0.27089168476783154,
        "total_hard_percision": 0.026470588235294128,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.05042016806722692,
        "total_hard_reciprocal_rank": 0.2901598673657497,
        "total_easy_percision": 0.02413793103448277,
        "total_easy_recall": 0.4827586206896552,
        "total_easy_f1_score": 0.0459770114942529,
        "total_easy_reciprocal_rank": 0.25394897248345527
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02522935779816512,
        "total_recall": 0.5045871559633027,
        "total_f1_score": 0.048055919615552625,
        "total_reciprocal_rank": 0.27089168476783154,
        "total_hard_percision": 0.026470588235294128,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.05042016806722692,
        "total_hard_reciprocal_rank": 0.2901598673657497,
        "total_easy_percision": 0.02413793103448277,
        "total_easy_recall": 0.4827586206896552,
        "total_easy_f1_score": 0.0459770114942529,
        "total_easy_reciprocal_rank": 0.25394897248345527
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.031039755351681932,
        "total_recall": 0.5045871559633027,
        "total_f1_score": 0.05674967234600258,
        "total_reciprocal_rank": 0.27089168476783154,
        "total_hard_percision": 0.03202614379084969,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.05835667600373486,
        "total_hard_reciprocal_rank": 0.2901598673657497,
        "total_easy_percision": 0.030172413793103467,
        "total_easy_recall": 0.4827586206896552,
        "total_easy_f1_score": 0.05533661740558296,
        "total_easy_reciprocal_rank": 0.25394897248345527
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.06624101298952885,
        "total_recall": 0.4954128440366973,
        "total_f1_score": 0.09565162716524654,
        "total_reciprocal_rank": 0.27028006397272447,
        "total_hard_percision": 0.05555166511048864,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.085090687858854,
        "total_hard_reciprocal_rank": 0.2901598673657497,
        "total_easy_percision": 0.0756402671590298,
        "total_easy_recall": 0.46551724137931033,
        "total_easy_f1_score": 0.10493797034845394,
        "total_easy_reciprocal_rank": 0.25279954719609893
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.11950401789851328,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.1484345420125236,
        "total_reciprocal_rank": 0.23473926684935856,
        "total_hard_percision": 0.10687901423195541,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.13881107998755057,
        "total_hard_reciprocal_rank": 0.25684718331777157,
        "total_easy_percision": 0.13060531422600383,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.15689655172413783,
        "total_easy_reciprocal_rank": 0.2152995471960989
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.11294597349643222,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.12262996941896023,
        "total_reciprocal_rank": 0.13149847094801223,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07375478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0839080459770115,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.012844036697247714,
        "total_recall": 0.6422018348623854,
        "total_f1_score": 0.025184385680877844,
        "total_reciprocal_rank": 0.26688436475969085,
        "total_hard_percision": 0.012156862745098043,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.023836985774702037,
        "total_hard_reciprocal_rank": 0.2770070129161451,
        "total_easy_percision": 0.013448275862068971,
        "total_easy_recall": 0.6724137931034483,
        "total_easy_f1_score": 0.02636916835699798,
        "total_easy_reciprocal_rank": 0.2579834155186708
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.012864424057084616,
        "total_recall": 0.6422018348623854,
        "total_f1_score": 0.025223491869823304,
        "total_reciprocal_rank": 0.26688436475969085,
        "total_hard_percision": 0.0122004357298475,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.02392056566872273,
        "total_hard_reciprocal_rank": 0.2770070129161451,
        "total_easy_percision": 0.013448275862068971,
        "total_easy_recall": 0.6724137931034483,
        "total_easy_f1_score": 0.02636916835699798,
        "total_easy_reciprocal_rank": 0.2579834155186708
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.019600226891585287,
        "total_recall": 0.6422018348623854,
        "total_f1_score": 0.03564834190556954,
        "total_reciprocal_rank": 0.26688436475969085,
        "total_hard_percision": 0.018316993464052297,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.03290335742139996,
        "total_hard_reciprocal_rank": 0.2770070129161451,
        "total_easy_percision": 0.020728587319243614,
        "total_easy_recall": 0.6724137931034483,
        "total_easy_f1_score": 0.038062035158891165,
        "total_easy_reciprocal_rank": 0.2579834155186708
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.06069934920716698,
        "total_recall": 0.6238532110091743,
        "total_f1_score": 0.08557195372041522,
        "total_reciprocal_rank": 0.2660775458384858,
        "total_hard_percision": 0.04767981209404701,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.07056111619395673,
        "total_hard_reciprocal_rank": 0.2770070129161451,
        "total_easy_percision": 0.07214756287560022,
        "total_easy_recall": 0.6379310344827587,
        "total_easy_f1_score": 0.09877113844195634,
        "total_easy_reciprocal_rank": 0.2564671523736476
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.11773935879482178,
        "total_recall": 0.45871559633027525,
        "total_f1_score": 0.1452627314856615,
        "total_reciprocal_rank": 0.22967472230193087,
        "total_hard_percision": 0.10429476841241547,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.13403441814482292,
        "total_hard_reciprocal_rank": 0.24336571594151482,
        "total_easy_percision": 0.12956132620004124,
        "total_easy_recall": 0.4827586206896552,
        "total_easy_f1_score": 0.15513590356122647,
        "total_easy_reciprocal_rank": 0.21763608996367617
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.11312945973496433,
        "total_recall": 0.1651376146788991,
        "total_f1_score": 0.12298974635725848,
        "total_reciprocal_rank": 0.13188073394495414,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07409961685823756,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.08458417849898581,
        "total_easy_reciprocal_rank": 0.09554597701149425
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.1292412989660696,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.15792094615624028,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574712
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.1292412989660696,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.15792094615624028,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574712
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.1292412989660696,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.15792094615624028,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574712
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03050458715596331,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04791029561671762,
        "total_reciprocal_rank": 0.1292412989660696,
        "total_hard_percision": 0.04705882352941178,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.06951871657754008,
        "total_hard_reciprocal_rank": 0.15792094615624028,
        "total_easy_percision": 0.015948275862068963,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.02890978753047719,
        "total_easy_reciprocal_rank": 0.10402298850574712
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.06447502548419978,
        "total_recall": 0.1651376146788991,
        "total_f1_score": 0.07651614440605266,
        "total_reciprocal_rank": 0.10278869957769039,
        "total_hard_percision": 0.0872549019607843,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.10409982174688057,
        "total_hard_reciprocal_rank": 0.12752878929349518,
        "total_easy_percision": 0.044444444444444446,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.05226153157187639,
        "total_easy_reciprocal_rank": 0.0810344827586207
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.010091743119266056,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.010842368640533779,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.018965517241379314,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.020376175548589344,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01513761467889909,
        "total_recall": 0.30275229357798167,
        "total_f1_score": 0.028833551769331604,
        "total_reciprocal_rank": 0.13566379070540172,
        "total_hard_percision": 0.018627450980392164,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.03548085901027079,
        "total_hard_reciprocal_rank": 0.18150195750814943,
        "total_easy_percision": 0.012068965517241381,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.09535781644781323
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01513761467889909,
        "total_recall": 0.30275229357798167,
        "total_f1_score": 0.028833551769331604,
        "total_reciprocal_rank": 0.13566379070540172,
        "total_hard_percision": 0.018627450980392164,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.03548085901027079,
        "total_hard_reciprocal_rank": 0.18150195750814943,
        "total_easy_percision": 0.012068965517241381,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.09535781644781323
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01513761467889909,
        "total_recall": 0.30275229357798167,
        "total_f1_score": 0.028833551769331604,
        "total_reciprocal_rank": 0.13566379070540172,
        "total_hard_percision": 0.018627450980392164,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.03548085901027079,
        "total_hard_reciprocal_rank": 0.18150195750814943,
        "total_easy_percision": 0.012068965517241381,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.09535781644781323
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.024541284403669705,
        "total_recall": 0.30275229357798167,
        "total_f1_score": 0.03829911169360712,
        "total_reciprocal_rank": 0.13566379070540172,
        "total_hard_percision": 0.03725490196078433,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.05322128851540619,
        "total_hard_reciprocal_rank": 0.18150195750814943,
        "total_easy_percision": 0.013362068965517246,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.025177887246852767,
        "total_easy_reciprocal_rank": 0.09535781644781323
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.06355759429153923,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.07540410659676713,
        "total_reciprocal_rank": 0.10778675867578641,
        "total_hard_percision": 0.08431372549019606,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.09934640522875816,
        "total_hard_reciprocal_rank": 0.14909741674447555,
        "total_easy_percision": 0.04530651340996167,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.05435139573070609,
        "total_easy_reciprocal_rank": 0.07146186968435288
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.011926605504587158,
        "total_recall": 0.06422018348623854,
        "total_f1_score": 0.014416775884665799,
        "total_reciprocal_rank": 0.022807017543859647,
        "total_hard_percision": 0.00196078431372549,
        "total_hard_recall": 0.0392156862745098,
        "total_hard_f1_score": 0.0037348272642390287,
        "total_hard_reciprocal_rank": 0.021568627450980395,
        "total_easy_percision": 0.020689655172413796,
        "total_easy_recall": 0.08620689655172414,
        "total_easy_f1_score": 0.023809523809523815,
        "total_easy_reciprocal_rank": 0.023895946763460376
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006605504587155966,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.012951969778737187,
        "total_reciprocal_rank": 0.12512872214060586,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.16040600570012334,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.09410904176930605
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006605504587155966,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.012951969778737187,
        "total_reciprocal_rank": 0.12512872214060586,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.16040600570012334,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.09410904176930605
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006605504587155966,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.012951969778737187,
        "total_reciprocal_rank": 0.12512872214060586,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.16040600570012334,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.09410904176930605
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.016559633027522943,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.02344546381243627,
        "total_reciprocal_rank": 0.12512872214060586,
        "total_hard_percision": 0.02705882352941177,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.0342176086120723,
        "total_hard_reciprocal_rank": 0.16040600570012334,
        "total_easy_percision": 0.007327586206896554,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.013973405454135673,
        "total_easy_reciprocal_rank": 0.09410904176930605
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.06022765885151204,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.06922365276385782,
        "total_reciprocal_rank": 0.09750645207507168,
        "total_hard_percision": 0.08058823529411764,
        "total_hard_recall": 0.27450980392156865,
        "total_hard_f1_score": 0.09242599000384466,
        "total_hard_reciprocal_rank": 0.12943722179016298,
        "total_easy_percision": 0.04232439335887612,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.04882159760455906,
        "total_easy_reciprocal_rank": 0.06942939594628457
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.010458715596330277,
        "total_recall": 0.07339449541284404,
        "total_f1_score": 0.011692750494693293,
        "total_reciprocal_rank": 0.01224870149082355,
        "total_hard_percision": 0.000784313725490196,
        "total_hard_recall": 0.0392156862745098,
        "total_hard_f1_score": 0.0015378700499807767,
        "total_hard_reciprocal_rank": 0.0013142554319024908,
        "total_easy_percision": 0.018965517241379314,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.020622041920216366,
        "total_easy_reciprocal_rank": 0.021863473025392068
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03486238532110093,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.06338615512927437,
        "total_reciprocal_rank": 0.2000364059997087,
        "total_hard_percision": 0.03333333333333334,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.060606060606060594,
        "total_hard_reciprocal_rank": 0.21427015250544665,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.18752052545155992
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03486238532110093,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.06338615512927437,
        "total_reciprocal_rank": 0.2000364059997087,
        "total_hard_percision": 0.03333333333333334,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.060606060606060594,
        "total_hard_reciprocal_rank": 0.21427015250544665,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.18752052545155992
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.055045871559633,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.08284681679177087,
        "total_reciprocal_rank": 0.2000364059997087,
        "total_hard_percision": 0.058823529411764726,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.08615567439096848,
        "total_hard_reciprocal_rank": 0.21427015250544665,
        "total_easy_percision": 0.0517241379310345,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.07993730407523507,
        "total_easy_reciprocal_rank": 0.18752052545155992
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08152031454783747,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.11286918993341008,
        "total_reciprocal_rank": 0.19748798602009607,
        "total_hard_percision": 0.09950202303143481,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.13134708428826075,
        "total_hard_reciprocal_rank": 0.21209150326797388,
        "total_easy_percision": 0.0657088122605364,
        "total_easy_recall": 0.3448275862068966,
        "total_easy_f1_score": 0.09662138627655867,
        "total_easy_reciprocal_rank": 0.18464696223316912
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08730886850152907,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.1031772508836729,
        "total_reciprocal_rank": 0.10389908256880734,
        "total_hard_percision": 0.08692810457516338,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.10067057125880656,
        "total_hard_reciprocal_rank": 0.10947712418300654,
        "total_easy_percision": 0.08764367816091953,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10538140020898643,
        "total_easy_reciprocal_rank": 0.09899425287356321
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02018348623853211,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.03844473569244213,
        "total_reciprocal_rank": 0.20257564341340295,
        "total_hard_percision": 0.019607843137254905,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.0373482726423903,
        "total_hard_reciprocal_rank": 0.21490698843640021,
        "total_easy_percision": 0.0206896551724138,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.03940886699507391,
        "total_easy_reciprocal_rank": 0.1917325641690433
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02063974881028308,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.03924566768603467,
        "total_reciprocal_rank": 0.20257564341340295,
        "total_hard_percision": 0.020409982174688063,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.03874883286647995,
        "total_hard_reciprocal_rank": 0.21490698843640021,
        "total_easy_percision": 0.020841784989858024,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.0396825396825397,
        "total_easy_reciprocal_rank": 0.1917325641690433
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.042331070525747694,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.06131564663674753,
        "total_reciprocal_rank": 0.20257564341340295,
        "total_hard_percision": 0.04733503308444119,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.06679116090880799,
        "total_hard_reciprocal_rank": 0.21490698843640021,
        "total_easy_percision": 0.03793103448275861,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.05650097029407377,
        "total_easy_reciprocal_rank": 0.1917325641690433
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.07836272155619159,
        "total_recall": 0.3577981651376147,
        "total_f1_score": 0.10767510507121947,
        "total_reciprocal_rank": 0.19820020234071414,
        "total_hard_percision": 0.09789088906735965,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.1287581699346405,
        "total_hard_reciprocal_rank": 0.21013071895424837,
        "total_easy_percision": 0.06119140184809555,
        "total_easy_recall": 0.3793103448275862,
        "total_easy_f1_score": 0.08913654803614234,
        "total_easy_reciprocal_rank": 0.18770957566329616
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.08623853211009175,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.10133200133200133,
        "total_reciprocal_rank": 0.10259938837920489,
        "total_hard_percision": 0.08594771241830064,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.09897292250233426,
        "total_hard_reciprocal_rank": 0.10588235294117648,
        "total_easy_percision": 0.08649425287356322,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10340636375119135,
        "total_easy_reciprocal_rank": 0.09971264367816092
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.01027522935779817,
        "total_recall": 0.5137614678899083,
        "total_f1_score": 0.02014750854470229,
        "total_reciprocal_rank": 0.2080396553349955,
        "total_hard_percision": 0.010196078431372551,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.019992310649750086,
        "total_hard_reciprocal_rank": 0.22092450621008222,
        "total_easy_percision": 0.0103448275862069,
        "total_easy_recall": 0.5172413793103449,
        "total_easy_f1_score": 0.020283975659229205,
        "total_easy_reciprocal_rank": 0.19670987266897094
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011394409952632894,
        "total_recall": 0.5137614678899083,
        "total_f1_score": 0.022189992204833,
        "total_reciprocal_rank": 0.2080396553349955,
        "total_hard_percision": 0.011826806969121965,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.022947904652056903,
        "total_hard_reciprocal_rank": 0.22092450621008222,
        "total_easy_percision": 0.011014198782961466,
        "total_easy_recall": 0.5172413793103449,
        "total_easy_f1_score": 0.021523551949515437,
        "total_easy_reciprocal_rank": 0.19670987266897094
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.035123807157237424,
        "total_recall": 0.5137614678899083,
        "total_f1_score": 0.04808080778129346,
        "total_reciprocal_rank": 0.2080396553349955,
        "total_hard_percision": 0.04191777685663365,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.05691892370093061,
        "total_hard_reciprocal_rank": 0.22092450621008222,
        "total_easy_percision": 0.029149799318113165,
        "total_easy_recall": 0.5172413793103449,
        "total_easy_f1_score": 0.040309361024371174,
        "total_easy_reciprocal_rank": 0.19670987266897094
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0769641559754052,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.1051386268689584,
        "total_reciprocal_rank": 0.19940413595180242,
        "total_hard_percision": 0.09812817938578589,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.1293213898750231,
        "total_hard_reciprocal_rank": 0.21446078431372553,
        "total_easy_percision": 0.058354411252484285,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.08387447319121187,
        "total_easy_reciprocal_rank": 0.18616466928873227
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.08568807339449541,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.10030406722257776,
        "total_reciprocal_rank": 0.10087659315820464,
        "total_hard_percision": 0.08535947712418299,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.09787444389520514,
        "total_hard_reciprocal_rank": 0.1050420168067227,
        "total_easy_percision": 0.08597701149425287,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10244046014837091,
        "total_easy_reciprocal_rank": 0.09721389305347326
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.2920816950633464,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.30543884220354806,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.2920816950633464,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.30543884220354806,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.2920816950633464,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.30543884220354806,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.049235474006116206,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.0850708924103419,
        "total_reciprocal_rank": 0.2920816950633464,
        "total_hard_percision": 0.054901960784313746,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.09447415329768268,
        "total_hard_reciprocal_rank": 0.30543884220354806,
        "total_easy_percision": 0.04425287356321841,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.07680250783699055,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.13923110528615112,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.1661205766710354,
        "total_reciprocal_rank": 0.27370030581039756,
        "total_hard_percision": 0.1426704014939309,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.17801969272557505,
        "total_hard_reciprocal_rank": 0.29084967320261434,
        "total_easy_percision": 0.1362068965517241,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.15565756082997464,
        "total_easy_reciprocal_rank": 0.25862068965517243
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.10871559633027522,
        "total_recall": 0.13761467889908258,
        "total_f1_score": 0.11542952460383653,
        "total_reciprocal_rank": 0.13761467889908258,
        "total_hard_percision": 0.14215686274509803,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.15163398692810456,
        "total_hard_reciprocal_rank": 0.17647058823529413,
        "total_easy_percision": 0.0793103448275862,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.08359456635318704,
        "total_easy_reciprocal_rank": 0.10344827586206896
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.023394495412844028,
        "total_recall": 0.46788990825688076,
        "total_f1_score": 0.04456094364351245,
        "total_reciprocal_rank": 0.2921729339497822,
        "total_hard_percision": 0.025490196078431383,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.048552754435107405,
        "total_hard_reciprocal_rank": 0.3171983053470943,
        "total_easy_percision": 0.021551724137931043,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.041050903119868656,
        "total_easy_reciprocal_rank": 0.27016786599697346
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.023394495412844028,
        "total_recall": 0.46788990825688076,
        "total_f1_score": 0.04456094364351245,
        "total_reciprocal_rank": 0.2921729339497822,
        "total_hard_percision": 0.025490196078431383,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.048552754435107405,
        "total_hard_reciprocal_rank": 0.3171983053470943,
        "total_easy_percision": 0.021551724137931043,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.041050903119868656,
        "total_easy_reciprocal_rank": 0.27016786599697346
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.023394495412844028,
        "total_recall": 0.46788990825688076,
        "total_f1_score": 0.04456094364351245,
        "total_reciprocal_rank": 0.2921729339497822,
        "total_hard_percision": 0.025490196078431383,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.048552754435107405,
        "total_hard_reciprocal_rank": 0.3171983053470943,
        "total_easy_percision": 0.021551724137931043,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.041050903119868656,
        "total_easy_reciprocal_rank": 0.27016786599697346
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0340978593272171,
        "total_recall": 0.46788990825688076,
        "total_f1_score": 0.05941459152468324,
        "total_reciprocal_rank": 0.2921729339497822,
        "total_hard_percision": 0.03725490196078433,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.06442577030812328,
        "total_hard_reciprocal_rank": 0.3171983053470943,
        "total_easy_percision": 0.03132183908045978,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.05500821018062401,
        "total_easy_reciprocal_rank": 0.27016786599697346
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.13825192391706156,
        "total_recall": 0.3761467889908257,
        "total_f1_score": 0.1649361162313132,
        "total_reciprocal_rank": 0.27325187928938605,
        "total_hard_percision": 0.1402571284924226,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.17436974789915963,
        "total_hard_reciprocal_rank": 0.3026091363461606,
        "total_easy_percision": 0.1364887267904509,
        "total_easy_recall": 0.3275862068965517,
        "total_easy_f1_score": 0.1566410263164827,
        "total_easy_reciprocal_rank": 0.2474377394636015
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.10825688073394496,
        "total_recall": 0.13761467889908258,
        "total_f1_score": 0.11463521188291831,
        "total_reciprocal_rank": 0.1290519877675841,
        "total_hard_percision": 0.14215686274509803,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.15163398692810456,
        "total_hard_reciprocal_rank": 0.17647058823529413,
        "total_easy_percision": 0.07844827586206896,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.08210180623973727,
        "total_easy_reciprocal_rank": 0.08735632183908046
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011926605504587162,
        "total_recall": 0.5963302752293578,
        "total_f1_score": 0.023385500989386576,
        "total_reciprocal_rank": 0.2969192574891902,
        "total_hard_percision": 0.012156862745098043,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.023836985774702037,
        "total_hard_reciprocal_rank": 0.31727752382997865,
        "total_easy_percision": 0.011724137931034488,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.2790180232929797
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011926605504587162,
        "total_recall": 0.5963302752293578,
        "total_f1_score": 0.023385500989386576,
        "total_reciprocal_rank": 0.2969192574891902,
        "total_hard_percision": 0.012156862745098043,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.023836985774702037,
        "total_hard_reciprocal_rank": 0.31727752382997865,
        "total_easy_percision": 0.011724137931034488,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.2790180232929797
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011926605504587162,
        "total_recall": 0.5963302752293578,
        "total_f1_score": 0.023385500989386576,
        "total_reciprocal_rank": 0.2969192574891902,
        "total_hard_percision": 0.012156862745098043,
        "total_hard_recall": 0.6078431372549019,
        "total_hard_f1_score": 0.023836985774702037,
        "total_hard_reciprocal_rank": 0.31727752382997865,
        "total_easy_percision": 0.011724137931034488,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.2790180232929797
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.02459323212362554,
        "total_recall": 0.5688073394495413,
        "total_f1_score": 0.04186760129135679,
        "total_reciprocal_rank": 0.29609716909279765,
        "total_hard_percision": 0.025755707634391597,
        "total_hard_recall": 0.5686274509803921,
        "total_hard_f1_score": 0.04307542803217543,
        "total_hard_reciprocal_rank": 0.315998751451462,
        "total_easy_percision": 0.023571055381400214,
        "total_easy_recall": 0.5689655172413793,
        "total_easy_f1_score": 0.0408055467433956,
        "total_easy_reciprocal_rank": 0.278597501846386
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.13690394254392474,
        "total_recall": 0.44036697247706424,
        "total_f1_score": 0.1625534453506133,
        "total_reciprocal_rank": 0.2757228575443618,
        "total_hard_percision": 0.1377984714701982,
        "total_hard_recall": 0.49019607843137253,
        "total_hard_f1_score": 0.169912049408188,
        "total_hard_reciprocal_rank": 0.3014095824505283,
        "total_easy_percision": 0.136117374005305,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.15608294867929756,
        "total_easy_reciprocal_rank": 0.2531362546096294
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 0.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.10834862385321099,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.11484079870480302,
        "total_reciprocal_rank": 0.13000802625295904,
        "total_hard_percision": 0.14254901960784314,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.15240292195309496,
        "total_hard_reciprocal_rank": 0.17740429505135388,
        "total_easy_percision": 0.07827586206896552,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.08181203515889114,
        "total_easy_reciprocal_rank": 0.08833199679230151
    },
    {
        "profile": {
            "profile_name": "mini nomic",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                },
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03944954128440368,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07172643869891572,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.03921568627450981,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07130124777183598,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "mini roberta",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                },
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04296636085626911,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07664720600500413,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.04379084967320263,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07754010695187163,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.04224137931034484,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07586206896551721,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "roberta nomic",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                },
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03577981651376149,
        "total_recall": 0.3577981651376147,
        "total_f1_score": 0.06505421184320263,
        "total_reciprocal_rank": 0.20111766419105861,
        "total_hard_percision": 0.03529411764705883,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.0641711229946524,
        "total_hard_reciprocal_rank": 0.21413009648303766,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.18967569786535302
    },
    {
        "profile": {
            "profile_name": "all",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                },
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                },
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 0.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03944954128440368,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.07172643869891572,
        "total_reciprocal_rank": 0.25696810834425504,
        "total_hard_percision": 0.03921568627450981,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.07130124777183598,
        "total_hard_reciprocal_rank": 0.2687052598817305,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "ANGULAR_JS_SEARCH",
            "index_requests": [],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    }
]