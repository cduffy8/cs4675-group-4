[
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.25926168632590646,
        "total_hard_percision": 0.04117647058823531,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.07486631016042779,
        "total_hard_reciprocal_rank": 0.2736072206660442,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.25926168632590646,
        "total_hard_percision": 0.04117647058823531,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.07486631016042779,
        "total_hard_reciprocal_rank": 0.2736072206660442,
        "total_easy_percision": 0.03965517241379311,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07210031347962381,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04480122324159021,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.0797053099805393,
        "total_reciprocal_rank": 0.25926168632590646,
        "total_hard_percision": 0.04575163398692812,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.08110516934046343,
        "total_hard_reciprocal_rank": 0.2736072206660442,
        "total_easy_percision": 0.04396551724137933,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.07847439916405431,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.07517838939857283,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.11026649191786801,
        "total_reciprocal_rank": 0.25926168632590646,
        "total_hard_percision": 0.06394335511982574,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.09851455733808671,
        "total_hard_reciprocal_rank": 0.2736072206660442,
        "total_easy_percision": 0.0850574712643678,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.12060008956560678,
        "total_easy_reciprocal_rank": 0.24664750957854403
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.1214758992281927,
        "total_recall": 0.3577981651376147,
        "total_f1_score": 0.15142115784317614,
        "total_reciprocal_rank": 0.22737003058103972,
        "total_hard_percision": 0.10761749144102087,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.13954955719661602,
        "total_hard_reciprocal_rank": 0.24466230936819172,
        "total_easy_percision": 0.13366174055829222,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.16185997910135833,
        "total_easy_reciprocal_rank": 0.2121647509578544
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.11294597349643222,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.12262996941896023,
        "total_reciprocal_rank": 0.13149847094801223,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07375478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0839080459770115,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02247706422018348,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.04281345565749236,
        "total_reciprocal_rank": 0.2626417542701946,
        "total_hard_percision": 0.02352941176470589,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.04481792717086837,
        "total_hard_reciprocal_rank": 0.27774156671215494,
        "total_easy_percision": 0.021551724137931043,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.041050903119868656,
        "total_easy_reciprocal_rank": 0.2493643329850226
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02247706422018348,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.04281345565749236,
        "total_reciprocal_rank": 0.2626417542701946,
        "total_hard_percision": 0.02352941176470589,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.04481792717086837,
        "total_hard_reciprocal_rank": 0.27774156671215494,
        "total_easy_percision": 0.021551724137931043,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.041050903119868656,
        "total_easy_reciprocal_rank": 0.2493643329850226
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.028287461773700288,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.0515072083879423,
        "total_reciprocal_rank": 0.2626417542701946,
        "total_hard_percision": 0.029084967320261453,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.05275443510737631,
        "total_hard_reciprocal_rank": 0.27774156671215494,
        "total_easy_percision": 0.02758620689655174,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.05041050903119872,
        "total_easy_reciprocal_rank": 0.2493643329850226
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.06348871941154721,
        "total_recall": 0.44036697247706424,
        "total_f1_score": 0.09040916320718627,
        "total_reciprocal_rank": 0.2620301334750875,
        "total_hard_percision": 0.05261048863990041,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.07948844696249542,
        "total_hard_reciprocal_rank": 0.27774156671215494,
        "total_easy_percision": 0.07305406026247808,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.10001186197406972,
        "total_easy_reciprocal_rank": 0.2482149076976663
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.11812787110952244,
        "total_recall": 0.3761467889908257,
        "total_f1_score": 0.14581331003349346,
        "total_reciprocal_rank": 0.22885936693276138,
        "total_hard_percision": 0.10491822991822992,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.13507625272331153,
        "total_hard_reciprocal_rank": 0.24606286959228135,
        "total_easy_percision": 0.12974324526048658,
        "total_easy_recall": 0.3793103448275862,
        "total_easy_f1_score": 0.15525451559934308,
        "total_easy_reciprocal_rank": 0.21373214907697663
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.11294597349643222,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.12262996941896023,
        "total_reciprocal_rank": 0.13149847094801223,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07375478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0839080459770115,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011192660550458722,
        "total_recall": 0.5596330275229358,
        "total_f1_score": 0.02194639323619356,
        "total_reciprocal_rank": 0.26620643454109744,
        "total_hard_percision": 0.01058823529411765,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.020761245674740476,
        "total_hard_reciprocal_rank": 0.2792956698348855,
        "total_easy_percision": 0.011724137931034488,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.2546969345413873
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011213047910295624,
        "total_recall": 0.5596330275229358,
        "total_f1_score": 0.02198549942513902,
        "total_reciprocal_rank": 0.26620643454109744,
        "total_hard_percision": 0.010631808278867106,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.02084482556876117,
        "total_hard_reciprocal_rank": 0.2792956698348855,
        "total_easy_percision": 0.011724137931034488,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.02298850574712644,
        "total_easy_reciprocal_rank": 0.2546969345413873
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.017948850744796296,
        "total_recall": 0.5596330275229358,
        "total_f1_score": 0.03241034946088526,
        "total_reciprocal_rank": 0.26620643454109744,
        "total_hard_percision": 0.016748366013071902,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.029827617321438397,
        "total_hard_reciprocal_rank": 0.2792956698348855,
        "total_easy_percision": 0.01900444938820913,
        "total_easy_recall": 0.5862068965517241,
        "total_easy_f1_score": 0.034681372549019644,
        "total_easy_reciprocal_rank": 0.2546969345413873
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.059047973060378,
        "total_recall": 0.5412844036697247,
        "total_f1_score": 0.08233396127573094,
        "total_reciprocal_rank": 0.2653953721823686,
        "total_hard_percision": 0.04611118464306661,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.06748537609399519,
        "total_hard_reciprocal_rank": 0.2792956698348855,
        "total_easy_percision": 0.07042342494456572,
        "total_easy_recall": 0.5517241379310345,
        "total_easy_f1_score": 0.09539047583208482,
        "total_easy_reciprocal_rank": 0.2531726966603278
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.11663844136362915,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.14310406985587196,
        "total_reciprocal_rank": 0.22982048532507243,
        "total_hard_percision": 0.1031182978241802,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.13172761306985173,
        "total_hard_reciprocal_rank": 0.24606286959228135,
        "total_easy_percision": 0.12852684344142057,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.1531075059953035,
        "total_easy_reciprocal_rank": 0.21553838881425086
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.11294597349643222,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.12262996941896023,
        "total_reciprocal_rank": 0.13149847094801223,
        "total_hard_percision": 0.15751633986928104,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.16666666666666666,
        "total_hard_reciprocal_rank": 0.17320261437908493,
        "total_easy_percision": 0.07375478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0839080459770115,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.13749817970001452,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.17556800497976965,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574711
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.13749817970001452,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.17556800497976965,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574711
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02201834862385322,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04003336113427856,
        "total_reciprocal_rank": 0.13749817970001452,
        "total_hard_percision": 0.029411764705882356,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.053475935828877004,
        "total_hard_reciprocal_rank": 0.17556800497976965,
        "total_easy_percision": 0.015517241379310343,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028213166144200632,
        "total_easy_reciprocal_rank": 0.10402298850574711
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03050458715596331,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.04791029561671762,
        "total_reciprocal_rank": 0.13749817970001452,
        "total_hard_percision": 0.04705882352941178,
        "total_hard_recall": 0.29411764705882354,
        "total_hard_f1_score": 0.06951871657754008,
        "total_hard_reciprocal_rank": 0.17556800497976965,
        "total_easy_percision": 0.015948275862068963,
        "total_easy_recall": 0.15517241379310345,
        "total_easy_f1_score": 0.028909787530477193,
        "total_easy_reciprocal_rank": 0.10402298850574711
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.06447502548419978,
        "total_recall": 0.1651376146788991,
        "total_f1_score": 0.07651614440605266,
        "total_reciprocal_rank": 0.10278869957769038,
        "total_hard_percision": 0.0872549019607843,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.10409982174688057,
        "total_hard_reciprocal_rank": 0.12752878929349518,
        "total_easy_percision": 0.044444444444444446,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.0522615315718764,
        "total_easy_reciprocal_rank": 0.08103448275862067
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.010091743119266056,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.010842368640533779,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.018965517241379314,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.020376175548589344,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 10 paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.012385321100917435,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.02359108781127131,
        "total_reciprocal_rank": 0.13913232442502185,
        "total_hard_percision": 0.015686274509803925,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.02987861811391224,
        "total_hard_reciprocal_rank": 0.1768751945222533,
        "total_easy_percision": 0.009482758620689653,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.0180623973727422,
        "total_easy_reciprocal_rank": 0.1059446283050425
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.012385321100917435,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.02359108781127131,
        "total_reciprocal_rank": 0.13913232442502185,
        "total_hard_percision": 0.015686274509803925,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.02987861811391224,
        "total_hard_reciprocal_rank": 0.1768751945222533,
        "total_easy_percision": 0.009482758620689653,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.0180623973727422,
        "total_easy_reciprocal_rank": 0.1059446283050425
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.012385321100917435,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.02359108781127131,
        "total_reciprocal_rank": 0.13913232442502185,
        "total_hard_percision": 0.015686274509803925,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.02987861811391224,
        "total_hard_reciprocal_rank": 0.1768751945222533,
        "total_easy_percision": 0.009482758620689653,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.0180623973727422,
        "total_easy_reciprocal_rank": 0.1059446283050425
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.021788990825688064,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.03305664773554683,
        "total_reciprocal_rank": 0.13913232442502185,
        "total_hard_percision": 0.03431372549019609,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.047619047619047644,
        "total_hard_reciprocal_rank": 0.1768751945222533,
        "total_easy_percision": 0.01077586206896552,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.020251778872468526,
        "total_easy_reciprocal_rank": 0.1059446283050425
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.061264016309887856,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.07103538663171689,
        "total_reciprocal_rank": 0.10332836498513776,
        "total_hard_percision": 0.08235294117647057,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.09561157796451913,
        "total_hard_reciprocal_rank": 0.12752878929349518,
        "total_easy_percision": 0.04272030651340995,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.049425287356321845,
        "total_easy_reciprocal_rank": 0.08204868154158214
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.00963302752293578,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.010048055919615554,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.01810344827586207,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.018883415435139574,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 20 paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006238532110091745,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.012232415902140675,
        "total_reciprocal_rank": 0.14105007391120514,
        "total_hard_percision": 0.007058823529411766,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.013840830449826985,
        "total_hard_reciprocal_rank": 0.17775359466279736,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.10877628842273614
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006238532110091745,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.012232415902140675,
        "total_reciprocal_rank": 0.14105007391120514,
        "total_hard_percision": 0.007058823529411766,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.013840830449826985,
        "total_hard_reciprocal_rank": 0.17775359466279736,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.10877628842273614
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006238532110091745,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.012232415902140675,
        "total_reciprocal_rank": 0.14105007391120514,
        "total_hard_percision": 0.007058823529411766,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.013840830449826985,
        "total_hard_reciprocal_rank": 0.17775359466279736,
        "total_easy_percision": 0.005517241379310345,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.010818120351588908,
        "total_easy_reciprocal_rank": 0.10877628842273614
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.01619266055045872,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.02272590993583976,
        "total_reciprocal_rank": 0.14105007391120514,
        "total_hard_percision": 0.026274509803921573,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.03267973856209152,
        "total_hard_reciprocal_rank": 0.17775359466279736,
        "total_easy_percision": 0.007327586206896554,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.013973405454135673,
        "total_easy_reciprocal_rank": 0.10877628842273614
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.05986068637444782,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.06850409888726132,
        "total_reciprocal_rank": 0.10464186943719393,
        "total_hard_percision": 0.07980392156862744,
        "total_hard_recall": 0.23529411764705882,
        "total_hard_f1_score": 0.0908881199538639,
        "total_hard_reciprocal_rank": 0.1280070293700136,
        "total_easy_percision": 0.04232439335887612,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.04882159760455906,
        "total_easy_reciprocal_rank": 0.08409664259971464
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.010275229357798166,
        "total_recall": 0.06422018348623854,
        "total_f1_score": 0.011332973556395037,
        "total_reciprocal_rank": 0.019662128305267187,
        "total_hard_percision": 0.000392156862745098,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0007689350249903883,
        "total_hard_reciprocal_rank": 0.00047824007651841227,
        "total_easy_percision": 0.018965517241379314,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.020622041920216366,
        "total_easy_reciprocal_rank": 0.03653071967882214
    },
    {
        "profile": {
            "profile_name": "BASE 50 paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03486238532110093,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.06338615512927437,
        "total_reciprocal_rank": 0.21494466288044267,
        "total_hard_percision": 0.03333333333333334,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.060606060606060594,
        "total_hard_reciprocal_rank": 0.2289760348583878,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.20260673234811163
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03486238532110093,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.06338615512927437,
        "total_reciprocal_rank": 0.21494466288044267,
        "total_hard_percision": 0.03333333333333334,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.060606060606060594,
        "total_hard_reciprocal_rank": 0.2289760348583878,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.20260673234811163
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.055045871559633,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.08284681679177087,
        "total_reciprocal_rank": 0.21494466288044267,
        "total_hard_percision": 0.058823529411764726,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.08615567439096848,
        "total_hard_reciprocal_rank": 0.2289760348583878,
        "total_easy_percision": 0.0517241379310345,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.07993730407523507,
        "total_easy_reciprocal_rank": 0.20260673234811163
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08152031454783747,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.11286918993341008,
        "total_reciprocal_rank": 0.21239624290083,
        "total_hard_percision": 0.09950202303143481,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.13134708428826075,
        "total_hard_reciprocal_rank": 0.22679738562091503,
        "total_easy_percision": 0.0657088122605364,
        "total_easy_recall": 0.3448275862068966,
        "total_easy_f1_score": 0.09662138627655867,
        "total_easy_reciprocal_rank": 0.19973316912972083
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08730886850152907,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.1031772508836729,
        "total_reciprocal_rank": 0.11880733944954128,
        "total_hard_percision": 0.08692810457516338,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.10067057125880656,
        "total_hard_reciprocal_rank": 0.1241830065359477,
        "total_easy_percision": 0.08764367816091953,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10538140020898643,
        "total_easy_reciprocal_rank": 0.11408045977011494
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 10 all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01972477064220184,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.03757099169943209,
        "total_reciprocal_rank": 0.2183007359612864,
        "total_hard_percision": 0.019607843137254905,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.0373482726423903,
        "total_hard_reciprocal_rank": 0.23320764203117142,
        "total_easy_percision": 0.019827586206896557,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.03776683087027916,
        "total_easy_reciprocal_rank": 0.20519293924466336
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.020181033213952808,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.038371923693024626,
        "total_reciprocal_rank": 0.2183007359612864,
        "total_hard_percision": 0.020409982174688063,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.03874883286647995,
        "total_hard_reciprocal_rank": 0.23320764203117142,
        "total_easy_percision": 0.01997971602434078,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.03804050355774496,
        "total_easy_reciprocal_rank": 0.20519293924466336
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.04187235492941741,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.060441902643737486,
        "total_reciprocal_rank": 0.2183007359612864,
        "total_hard_percision": 0.04733503308444119,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.06679116090880799,
        "total_hard_reciprocal_rank": 0.23320764203117142,
        "total_easy_percision": 0.03706896551724138,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.054858934169279026,
        "total_easy_reciprocal_rank": 0.20519293924466336
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0779040059598613,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.10680136107820942,
        "total_reciprocal_rank": 0.21392529488859766,
        "total_hard_percision": 0.09789088906735965,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.1287581699346405,
        "total_hard_reciprocal_rank": 0.2284313725490196,
        "total_easy_percision": 0.060329332882578315,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.0874945119113476,
        "total_easy_reciprocal_rank": 0.20116995073891625
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.08623853211009175,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.10133200133200133,
        "total_reciprocal_rank": 0.11880733944954128,
        "total_hard_percision": 0.08594771241830064,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.09897292250233426,
        "total_hard_reciprocal_rank": 0.1241830065359477,
        "total_easy_percision": 0.08649425287356322,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10340636375119135,
        "total_easy_reciprocal_rank": 0.11408045977011494
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 20 all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.010642201834862391,
        "total_recall": 0.5321100917431193,
        "total_f1_score": 0.020867062421298797,
        "total_reciprocal_rank": 0.22205005289596366,
        "total_hard_percision": 0.01058823529411765,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.020761245674740476,
        "total_hard_reciprocal_rank": 0.23673888074038216,
        "total_easy_percision": 0.010689655172413796,
        "total_easy_recall": 0.5344827586206896,
        "total_easy_f1_score": 0.020960108181203516,
        "total_easy_reciprocal_rank": 0.209134014618975
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011761382429697114,
        "total_recall": 0.5321100917431193,
        "total_f1_score": 0.02290954608142951,
        "total_reciprocal_rank": 0.22205005289596366,
        "total_hard_percision": 0.012218963831867064,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.023716839677047293,
        "total_hard_reciprocal_rank": 0.23673888074038216,
        "total_easy_percision": 0.011359026369168362,
        "total_easy_recall": 0.5344827586206896,
        "total_easy_f1_score": 0.022199684471489747,
        "total_easy_reciprocal_rank": 0.209134014618975
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.035490779634301646,
        "total_recall": 0.5321100917431193,
        "total_f1_score": 0.048800361657889965,
        "total_reciprocal_rank": 0.22205005289596366,
        "total_hard_percision": 0.042309933719378745,
        "total_hard_recall": 0.5294117647058824,
        "total_hard_f1_score": 0.057687858725921005,
        "total_hard_reciprocal_rank": 0.23673888074038216,
        "total_easy_percision": 0.029494626904320063,
        "total_easy_recall": 0.5344827586206896,
        "total_easy_f1_score": 0.04098549354634548,
        "total_easy_reciprocal_rank": 0.209134014618975
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0771476422139373,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.10549840380725665,
        "total_reciprocal_rank": 0.21525258045452714,
        "total_hard_percision": 0.09852033624853097,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.1300903249000135,
        "total_hard_reciprocal_rank": 0.2302751588440254,
        "total_easy_percision": 0.058354411252484285,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.08387447319121187,
        "total_easy_reciprocal_rank": 0.20204307187065804
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.08568807339449541,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.10030406722257776,
        "total_reciprocal_rank": 0.11880733944954128,
        "total_hard_percision": 0.08535947712418299,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.09787444389520514,
        "total_hard_reciprocal_rank": 0.1241830065359477,
        "total_easy_percision": 0.08597701149425287,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.10244046014837091,
        "total_easy_reciprocal_rank": 0.11408045977011494
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.016819571865443424,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.019877675840978593,
        "total_reciprocal_rank": 0.016819571865443424,
        "total_hard_percision": 0.00980392156862745,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0130718954248366,
        "total_hard_reciprocal_rank": 0.00980392156862745,
        "total_easy_percision": 0.022988505747126436,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.02586206896551724,
        "total_easy_reciprocal_rank": 0.022988505747126436
    },
    {
        "profile": {
            "profile_name": "BASE 50 all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.30033857579729145,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.3230859010270775,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.30033857579729145,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.3230859010270775,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04036697247706422,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.073394495412844,
        "total_reciprocal_rank": 0.30033857579729145,
        "total_hard_percision": 0.04509803921568629,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.08199643493761138,
        "total_hard_reciprocal_rank": 0.3230859010270775,
        "total_easy_percision": 0.03620689655172415,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.06583072100313478,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.049235474006116206,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.0850708924103419,
        "total_reciprocal_rank": 0.30033857579729145,
        "total_hard_percision": 0.054901960784313746,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.09447415329768268,
        "total_hard_reciprocal_rank": 0.3230859010270775,
        "total_easy_percision": 0.04425287356321841,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.07680250783699055,
        "total_easy_reciprocal_rank": 0.2803366174055829
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.13923110528615112,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.1661205766710354,
        "total_reciprocal_rank": 0.2819571865443425,
        "total_hard_percision": 0.1426704014939309,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.17801969272557505,
        "total_hard_reciprocal_rank": 0.3084967320261438,
        "total_easy_percision": 0.1362068965517241,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.15565756082997464,
        "total_easy_reciprocal_rank": 0.25862068965517243
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.10963302752293577,
        "total_recall": 0.14678899082568808,
        "total_f1_score": 0.1170975813177648,
        "total_reciprocal_rank": 0.14678899082568808,
        "total_hard_percision": 0.14411764705882352,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.15519904931669637,
        "total_hard_reciprocal_rank": 0.19607843137254902,
        "total_easy_percision": 0.0793103448275862,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.08359456635318704,
        "total_easy_reciprocal_rank": 0.10344827586206896
    },
    {
        "profile": {
            "profile_name": "BASE 10 nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02247706422018348,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.04281345565749236,
        "total_reciprocal_rank": 0.30295970069985184,
        "total_hard_percision": 0.024509803921568638,
        "total_hard_recall": 0.49019607843137253,
        "total_hard_f1_score": 0.04668534080298789,
        "total_hard_reciprocal_rank": 0.3252196957214259,
        "total_easy_percision": 0.0206896551724138,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.03940886699507391,
        "total_easy_reciprocal_rank": 0.2833862568015712
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02247706422018348,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.04281345565749236,
        "total_reciprocal_rank": 0.30295970069985184,
        "total_hard_percision": 0.024509803921568638,
        "total_hard_recall": 0.49019607843137253,
        "total_hard_f1_score": 0.04668534080298789,
        "total_hard_reciprocal_rank": 0.3252196957214259,
        "total_easy_percision": 0.0206896551724138,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.03940886699507391,
        "total_easy_reciprocal_rank": 0.2833862568015712
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02247706422018348,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.04281345565749236,
        "total_reciprocal_rank": 0.30295970069985184,
        "total_hard_percision": 0.024509803921568638,
        "total_hard_recall": 0.49019607843137253,
        "total_hard_f1_score": 0.04668534080298789,
        "total_hard_reciprocal_rank": 0.3252196957214259,
        "total_easy_percision": 0.0206896551724138,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.03940886699507391,
        "total_easy_reciprocal_rank": 0.2833862568015712
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.03318042813455656,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.057667103538663146,
        "total_reciprocal_rank": 0.30295970069985184,
        "total_hard_percision": 0.036274509803921585,
        "total_hard_recall": 0.49019607843137253,
        "total_hard_f1_score": 0.06255835667600376,
        "total_hard_reciprocal_rank": 0.3252196957214259,
        "total_easy_percision": 0.03045977011494254,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.05336617405582926,
        "total_easy_reciprocal_rank": 0.2833862568015712
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.137334492724401,
        "total_recall": 0.3577981651376147,
        "total_f1_score": 0.16318862824529312,
        "total_reciprocal_rank": 0.28403864603945556,
        "total_hard_percision": 0.13927673633555987,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.17250233426704012,
        "total_hard_reciprocal_rank": 0.31063052672049213,
        "total_easy_percision": 0.13562665782493366,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.15499899019168795,
        "total_easy_reciprocal_rank": 0.2606561302681992
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.10871559633027522,
        "total_recall": 0.14678899082568808,
        "total_f1_score": 0.11550895587592835,
        "total_reciprocal_rank": 0.14678899082568808,
        "total_hard_percision": 0.14313725490196078,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.1535014005602241,
        "total_hard_reciprocal_rank": 0.19607843137254902,
        "total_easy_percision": 0.07844827586206896,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.08210180623973727,
        "total_easy_reciprocal_rank": 0.10344827586206896
    },
    {
        "profile": {
            "profile_name": "BASE 20 nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011009174311926611,
        "total_recall": 0.5504587155963303,
        "total_f1_score": 0.021586616297895305,
        "total_reciprocal_rank": 0.30622438278949526,
        "total_hard_percision": 0.010980392156862749,
        "total_hard_recall": 0.5490196078431373,
        "total_hard_f1_score": 0.021530180699730866,
        "total_hard_reciprocal_rank": 0.3270193404987056,
        "total_easy_percision": 0.011034482758620694,
        "total_easy_recall": 0.5517241379310345,
        "total_easy_f1_score": 0.021636240703177823,
        "total_easy_reciprocal_rank": 0.28793916135553427
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011009174311926611,
        "total_recall": 0.5504587155963303,
        "total_f1_score": 0.021586616297895305,
        "total_reciprocal_rank": 0.30622438278949526,
        "total_hard_percision": 0.010980392156862749,
        "total_hard_recall": 0.5490196078431373,
        "total_hard_f1_score": 0.021530180699730866,
        "total_hard_reciprocal_rank": 0.3270193404987056,
        "total_easy_percision": 0.011034482758620694,
        "total_easy_recall": 0.5517241379310345,
        "total_easy_f1_score": 0.021636240703177823,
        "total_easy_reciprocal_rank": 0.28793916135553427
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.011009174311926611,
        "total_recall": 0.5504587155963303,
        "total_f1_score": 0.021586616297895305,
        "total_reciprocal_rank": 0.30622438278949526,
        "total_hard_percision": 0.010980392156862749,
        "total_hard_recall": 0.5490196078431373,
        "total_hard_f1_score": 0.021530180699730866,
        "total_hard_reciprocal_rank": 0.3270193404987056,
        "total_easy_percision": 0.011034482758620694,
        "total_easy_recall": 0.5517241379310345,
        "total_easy_f1_score": 0.021636240703177823,
        "total_easy_reciprocal_rank": 0.28793916135553427
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.02367580093096499,
        "total_recall": 0.5229357798165137,
        "total_f1_score": 0.04006871659986552,
        "total_reciprocal_rank": 0.30540653783062655,
        "total_hard_percision": 0.0245792370461563,
        "total_hard_recall": 0.5098039215686274,
        "total_hard_f1_score": 0.04076862295720427,
        "total_hard_reciprocal_rank": 0.32574963742783813,
        "total_easy_percision": 0.02288140020898642,
        "total_easy_recall": 0.5344827586206896,
        "total_easy_f1_score": 0.03945328169944699,
        "total_easy_reciprocal_rank": 0.2875186399089405
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.13598651135126422,
        "total_recall": 0.3944954128440367,
        "total_f1_score": 0.16075456065912203,
        "total_reciprocal_rank": 0.2850260357883132,
        "total_hard_percision": 0.1366220008819629,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.16760524433321686,
        "total_hard_reciprocal_rank": 0.3111604684269044,
        "total_easy_percision": 0.1354277188328912,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.15473068363534895,
        "total_easy_reciprocal_rank": 0.2620457588130002
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.10816513761467889,
        "total_recall": 0.14678899082568808,
        "total_f1_score": 0.11448102176650476,
        "total_reciprocal_rank": 0.14678899082568808,
        "total_hard_percision": 0.14254901960784314,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.15240292195309496,
        "total_hard_reciprocal_rank": 0.19607843137254902,
        "total_easy_percision": 0.07793103448275861,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.08113590263691683,
        "total_easy_reciprocal_rank": 0.10344827586206896
    },
    {
        "profile": {
            "profile_name": "BASE 50 nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0,
        "total_recall": 0.0,
        "total_f1_score": 0.0,
        "total_reciprocal_rank": 0.0,
        "total_hard_percision": 0.0,
        "total_hard_recall": 0.0,
        "total_hard_f1_score": 0.0,
        "total_hard_reciprocal_rank": 0.0,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02477064220183487,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.04503753127606337,
        "total_reciprocal_rank": 0.19245667686034656,
        "total_hard_percision": 0.025490196078431372,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.04634581105169341,
        "total_hard_reciprocal_rank": 0.20326797385620915,
        "total_easy_percision": 0.024137931034482762,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.0438871473354232,
        "total_easy_reciprocal_rank": 0.18295019157088122
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.02477064220183487,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.04503753127606337,
        "total_reciprocal_rank": 0.19245667686034656,
        "total_hard_percision": 0.025490196078431372,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.04634581105169341,
        "total_hard_reciprocal_rank": 0.20326797385620915,
        "total_easy_percision": 0.024137931034482762,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.0438871473354232,
        "total_easy_reciprocal_rank": 0.18295019157088122
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.027304499781564014,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.048582151793160944,
        "total_reciprocal_rank": 0.19245667686034656,
        "total_hard_percision": 0.026330532212885158,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.047682709447415324,
        "total_hard_reciprocal_rank": 0.20326797385620915,
        "total_easy_percision": 0.028160919540229895,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.04937304075235109,
        "total_easy_reciprocal_rank": 0.18295019157088122
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.040366972477064215,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.1878695208970438,
        "total_hard_percision": 0.0431372549019608,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.0623885918003565,
        "total_hard_reciprocal_rank": 0.20326797385620915,
        "total_easy_percision": 0.037931034482758634,
        "total_easy_recall": 0.22413793103448276,
        "total_easy_f1_score": 0.05485893416927898,
        "total_easy_reciprocal_rank": 0.1743295019157088
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.060761613513907096,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.0837688814753035,
        "total_reciprocal_rank": 0.1878695208970438,
        "total_hard_percision": 0.060177404295051355,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.08710635769459298,
        "total_hard_reciprocal_rank": 0.20326797385620915,
        "total_easy_percision": 0.061275314723590595,
        "total_easy_recall": 0.22413793103448276,
        "total_easy_f1_score": 0.08083420411006617,
        "total_easy_reciprocal_rank": 0.1743295019157088
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08042813455657491,
        "total_recall": 0.13761467889908258,
        "total_f1_score": 0.09266849358592479,
        "total_reciprocal_rank": 0.12232415902140674,
        "total_hard_percision": 0.11601307189542483,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.13202614379084968,
        "total_hard_reciprocal_rank": 0.15359477124183005,
        "total_easy_percision": 0.04913793103448276,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.05806090461262875,
        "total_easy_reciprocal_rank": 0.09482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.022935779816513763,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.024464831804281346,
        "total_reciprocal_rank": 0.027522935779816515,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.02586206896551724,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.028735632183908042,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.015596330275229366,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.029707295762341653,
        "total_reciprocal_rank": 0.19653176843543815,
        "total_hard_percision": 0.01666666666666667,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.03174603174603176,
        "total_hard_reciprocal_rank": 0.20879120879120877,
        "total_easy_percision": 0.014655172413793107,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.02791461412151068,
        "total_easy_reciprocal_rank": 0.18575191570881225
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.015596330275229366,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.029707295762341653,
        "total_reciprocal_rank": 0.19653176843543815,
        "total_hard_percision": 0.01666666666666667,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.03174603174603176,
        "total_hard_reciprocal_rank": 0.20879120879120877,
        "total_easy_percision": 0.014655172413793107,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.02791461412151068,
        "total_easy_reciprocal_rank": 0.18575191570881225
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.019506334643949328,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.035634854442193914,
        "total_reciprocal_rank": 0.19653176843543815,
        "total_hard_percision": 0.0184873949579832,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.03478057889822597,
        "total_hard_reciprocal_rank": 0.20879120879120877,
        "total_easy_percision": 0.02040229885057472,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.03638602776533813,
        "total_easy_reciprocal_rank": 0.18575191570881225
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.03301968164353484,
        "total_recall": 0.30275229357798167,
        "total_f1_score": 0.04623657768273895,
        "total_reciprocal_rank": 0.1919446124721354,
        "total_hard_percision": 0.035729847494553386,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.05026659786721708,
        "total_hard_reciprocal_rank": 0.20879120879120877,
        "total_easy_percision": 0.030636604774535815,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.0426929392446634,
        "total_easy_reciprocal_rank": 0.17713122605363985
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.05974224552206204,
        "total_recall": 0.27522935779816515,
        "total_f1_score": 0.08233333006389501,
        "total_reciprocal_rank": 0.1902571943856347,
        "total_hard_percision": 0.06028633675692498,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.08781222217754725,
        "total_hard_reciprocal_rank": 0.20739064856711914,
        "total_easy_percision": 0.05926382047071703,
        "total_easy_recall": 0.2413793103448276,
        "total_easy_f1_score": 0.07751568355016633,
        "total_easy_reciprocal_rank": 0.17519157088122606
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.0808868501529052,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.09362166885102666,
        "total_reciprocal_rank": 0.1235474006116208,
        "total_hard_percision": 0.11699346405228757,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.13389355742296918,
        "total_hard_reciprocal_rank": 0.15522875816993462,
        "total_easy_percision": 0.04913793103448276,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.05821018062397373,
        "total_easy_reciprocal_rank": 0.09568965517241379
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.022935779816513763,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.024464831804281346,
        "total_reciprocal_rank": 0.027522935779816515,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.02586206896551724,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.028735632183908042,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0089908256880734,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.017629069976614512,
        "total_reciprocal_rank": 0.2003443321222641,
        "total_hard_percision": 0.009019607843137257,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.017685505574778923,
        "total_hard_reciprocal_rank": 0.21171417787875293,
        "total_easy_percision": 0.008965517241379313,
        "total_easy_recall": 0.4482758620689655,
        "total_easy_f1_score": 0.017579445571331974,
        "total_easy_reciprocal_rank": 0.19034670912948948
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.0089908256880734,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.017629069976614512,
        "total_reciprocal_rank": 0.2003443321222641,
        "total_hard_percision": 0.009019607843137257,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.017685505574778923,
        "total_hard_reciprocal_rank": 0.21171417787875293,
        "total_easy_percision": 0.008965517241379313,
        "total_easy_recall": 0.4482758620689655,
        "total_easy_f1_score": 0.017579445571331974,
        "total_easy_reciprocal_rank": 0.19034670912948948
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.01372651813018786,
        "total_recall": 0.44954128440366975,
        "total_f1_score": 0.02509852982060213,
        "total_reciprocal_rank": 0.2003443321222641,
        "total_hard_percision": 0.011428571428571432,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.021818531334102265,
        "total_hard_reciprocal_rank": 0.21171417787875293,
        "total_easy_percision": 0.015747126436781615,
        "total_easy_recall": 0.4482758620689655,
        "total_easy_f1_score": 0.027982666420800315,
        "total_easy_reciprocal_rank": 0.19034670912948948
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.028372710752964655,
        "total_recall": 0.44036697247706424,
        "total_f1_score": 0.03782668624358371,
        "total_reciprocal_rank": 0.19575717615896135,
        "total_hard_percision": 0.029958102899279374,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.039712964649224004,
        "total_hard_reciprocal_rank": 0.21171417787875293,
        "total_easy_percision": 0.026978659038101708,
        "total_easy_recall": 0.43103448275862066,
        "total_easy_f1_score": 0.03616806212827938,
        "total_easy_reciprocal_rank": 0.18172601947431705
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.05921822351433233,
        "total_recall": 0.3394495412844037,
        "total_f1_score": 0.08148754389231519,
        "total_reciprocal_rank": 0.1919187398948254,
        "total_hard_percision": 0.06016704428469135,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.08778409687987677,
        "total_hard_reciprocal_rank": 0.2098234215762319,
        "total_easy_percision": 0.058383915595568395,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.0759509197135972,
        "total_easy_reciprocal_rank": 0.17617496807151978
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.08054061654188197,
        "total_recall": 0.1559633027522936,
        "total_f1_score": 0.09298171041290307,
        "total_reciprocal_rank": 0.1235474006116208,
        "total_hard_percision": 0.11668920441739913,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.13333333333333333,
        "total_hard_reciprocal_rank": 0.15522875816993462,
        "total_easy_percision": 0.04875478927203065,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.05750011094838681,
        "total_easy_reciprocal_rank": 0.09568965517241379
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.022935779816513763,
        "total_recall": 0.027522935779816515,
        "total_f1_score": 0.024464831804281346,
        "total_reciprocal_rank": 0.027522935779816515,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.02586206896551724,
        "total_easy_recall": 0.034482758620689655,
        "total_easy_f1_score": 0.028735632183908042,
        "total_easy_reciprocal_rank": 0.034482758620689655
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550463,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.03169307756463719,
        "total_reciprocal_rank": 0.12852774137177808,
        "total_hard_percision": 0.02156862745098039,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.03921568627450981,
        "total_hard_reciprocal_rank": 0.16666666666666666,
        "total_easy_percision": 0.01379310344827586,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.02507836990595612,
        "total_easy_reciprocal_rank": 0.09499178981937605
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550463,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.03169307756463719,
        "total_reciprocal_rank": 0.12852774137177808,
        "total_hard_percision": 0.02156862745098039,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.03921568627450981,
        "total_hard_reciprocal_rank": 0.16666666666666666,
        "total_easy_percision": 0.01379310344827586,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.02507836990595612,
        "total_easy_reciprocal_rank": 0.09499178981937605
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550463,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.03169307756463719,
        "total_reciprocal_rank": 0.12852774137177808,
        "total_hard_percision": 0.02156862745098039,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.03921568627450981,
        "total_hard_reciprocal_rank": 0.16666666666666666,
        "total_easy_percision": 0.01379310344827586,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.02507836990595612,
        "total_easy_reciprocal_rank": 0.09499178981937605
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550463,
        "total_recall": 0.1743119266055046,
        "total_f1_score": 0.03169307756463719,
        "total_reciprocal_rank": 0.12852774137177808,
        "total_hard_percision": 0.02156862745098039,
        "total_hard_recall": 0.21568627450980393,
        "total_hard_f1_score": 0.03921568627450981,
        "total_hard_reciprocal_rank": 0.16666666666666666,
        "total_easy_percision": 0.01379310344827586,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.02507836990595612,
        "total_easy_reciprocal_rank": 0.09499178981937605
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.025229357798165146,
        "total_recall": 0.1651376146788991,
        "total_f1_score": 0.040922991381706963,
        "total_reciprocal_rank": 0.1269986893840105,
        "total_hard_percision": 0.030392156862745108,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.04943553178847296,
        "total_hard_reciprocal_rank": 0.16339869281045752,
        "total_easy_percision": 0.020689655172413796,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.03343782654127482,
        "total_easy_reciprocal_rank": 0.09499178981937605
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.07042376583660988,
        "total_recall": 0.14678899082568808,
        "total_f1_score": 0.08249930497636919,
        "total_reciprocal_rank": 0.12210572302315423,
        "total_hard_percision": 0.09953314659197011,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.11631016042780748,
        "total_hard_reciprocal_rank": 0.1568627450980392,
        "total_easy_percision": 0.04482758620689655,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.05276907001044931,
        "total_easy_reciprocal_rank": 0.09154351395730707
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.01834862385321101,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.01834862385321101,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.017241379310344827,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.017241379310344827,
        "total_easy_reciprocal_rank": 0.017241379310344827
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01192660550458716,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.022717343818261262,
        "total_reciprocal_rank": 0.133211394003282,
        "total_hard_percision": 0.013725490196078433,
        "total_hard_recall": 0.27450980392156865,
        "total_hard_f1_score": 0.026143790849673207,
        "total_hard_reciprocal_rank": 0.17029627865541178,
        "total_easy_percision": 0.010344827586206896,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.019704433497536946,
        "total_easy_reciprocal_rank": 0.10060227129192646
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01192660550458716,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.022717343818261262,
        "total_reciprocal_rank": 0.133211394003282,
        "total_hard_percision": 0.013725490196078433,
        "total_hard_recall": 0.27450980392156865,
        "total_hard_f1_score": 0.026143790849673207,
        "total_hard_reciprocal_rank": 0.17029627865541178,
        "total_easy_percision": 0.010344827586206896,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.019704433497536946,
        "total_easy_reciprocal_rank": 0.10060227129192646
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01192660550458716,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.022717343818261262,
        "total_reciprocal_rank": 0.133211394003282,
        "total_hard_percision": 0.013725490196078433,
        "total_hard_recall": 0.27450980392156865,
        "total_hard_f1_score": 0.026143790849673207,
        "total_hard_reciprocal_rank": 0.17029627865541178,
        "total_easy_percision": 0.010344827586206896,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.019704433497536946,
        "total_easy_reciprocal_rank": 0.10060227129192646
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01192660550458716,
        "total_recall": 0.23853211009174313,
        "total_f1_score": 0.022717343818261262,
        "total_reciprocal_rank": 0.133211394003282,
        "total_hard_percision": 0.013725490196078433,
        "total_hard_recall": 0.27450980392156865,
        "total_hard_f1_score": 0.026143790849673207,
        "total_hard_reciprocal_rank": 0.17029627865541178,
        "total_easy_percision": 0.010344827586206896,
        "total_easy_recall": 0.20689655172413793,
        "total_easy_f1_score": 0.019704433497536946,
        "total_easy_reciprocal_rank": 0.10060227129192646
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.02152140672782874,
        "total_recall": 0.22018348623853212,
        "total_f1_score": 0.03499403995896172,
        "total_reciprocal_rank": 0.13107072122040736,
        "total_hard_percision": 0.026388888888888892,
        "total_hard_recall": 0.2549019607843137,
        "total_hard_f1_score": 0.04304515169567073,
        "total_hard_reciprocal_rank": 0.16702830479920264,
        "total_easy_percision": 0.01724137931034483,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.02791461412151068,
        "total_easy_reciprocal_rank": 0.09945284600457015
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.06879277704965778,
        "total_recall": 0.14678899082568808,
        "total_f1_score": 0.07968707214240772,
        "total_reciprocal_rank": 0.12210572302315423,
        "total_hard_percision": 0.09855275443510737,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.1146125116713352,
        "total_hard_reciprocal_rank": 0.1568627450980392,
        "total_easy_percision": 0.042624521072796934,
        "total_easy_recall": 0.1206896551724138,
        "total_easy_f1_score": 0.048976771866971504,
        "total_easy_reciprocal_rank": 0.09154351395730707
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.01834862385321101,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.01834862385321101,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.017241379310344827,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.017241379310344827,
        "total_easy_reciprocal_rank": 0.017241379310344827
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006972477064220187,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.013671523655333697,
        "total_reciprocal_rank": 0.136954513987712,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.174705113994554,
        "total_easy_percision": 0.0062068965517241385,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.01217038539553752,
        "total_easy_reciprocal_rank": 0.10376002087824747
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006972477064220187,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.013671523655333697,
        "total_reciprocal_rank": 0.136954513987712,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.174705113994554,
        "total_easy_percision": 0.0062068965517241385,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.01217038539553752,
        "total_easy_reciprocal_rank": 0.10376002087824747
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.006972477064220187,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.013671523655333697,
        "total_reciprocal_rank": 0.136954513987712,
        "total_hard_percision": 0.007843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.01537870049980776,
        "total_hard_reciprocal_rank": 0.174705113994554,
        "total_easy_percision": 0.0062068965517241385,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.01217038539553752,
        "total_easy_reciprocal_rank": 0.10376002087824747
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.007145169994603349,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.014000462570349245,
        "total_reciprocal_rank": 0.136954513987712,
        "total_hard_percision": 0.008027681660899655,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.015730213654089078,
        "total_hard_reciprocal_rank": 0.174705113994554,
        "total_easy_percision": 0.0063691683569979726,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.01247947454844006,
        "total_easy_reciprocal_rank": 0.10376002087824747
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.018550178551792616,
        "total_recall": 0.3119266055045872,
        "total_f1_score": 0.029625758058292494,
        "total_reciprocal_rank": 0.13419891435137843,
        "total_hard_percision": 0.023625607256507888,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.038113496096426454,
        "total_hard_reciprocal_rank": 0.17143714013834485,
        "total_easy_percision": 0.014087301587301591,
        "total_easy_recall": 0.25862068965517243,
        "total_easy_f1_score": 0.022162402197174733,
        "total_easy_reciprocal_rank": 0.10145495719387344
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.06890325549179917,
        "total_recall": 0.1651376146788991,
        "total_f1_score": 0.07993540245854817,
        "total_reciprocal_rank": 0.12277850589777195,
        "total_hard_percision": 0.09893337727247761,
        "total_hard_recall": 0.19607843137254902,
        "total_hard_f1_score": 0.11537384184443007,
        "total_hard_reciprocal_rank": 0.15751633986928104,
        "total_easy_percision": 0.042497458753616386,
        "total_easy_recall": 0.13793103448275862,
        "total_easy_f1_score": 0.048774016101996845,
        "total_easy_reciprocal_rank": 0.09223316912972086
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-paraphrase-MiniLM-L6-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-paraphrase-MiniLM-L6-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.01834862385321101,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.01834862385321101,
        "total_reciprocal_rank": 0.01834862385321101,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.017241379310344827,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.017241379310344827,
        "total_easy_reciprocal_rank": 0.017241379310344827
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03211009174311928,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.20881753312945972,
        "total_hard_percision": 0.03725490196078433,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.06773618538324419,
        "total_hard_reciprocal_rank": 0.22581699346405226,
        "total_easy_percision": 0.02758620689655173,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.05015673981191222,
        "total_easy_reciprocal_rank": 0.19386973180076628
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03211009174311928,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.20881753312945972,
        "total_hard_percision": 0.03725490196078433,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.06773618538324419,
        "total_hard_reciprocal_rank": 0.22581699346405226,
        "total_easy_percision": 0.02758620689655173,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.05015673981191222,
        "total_easy_reciprocal_rank": 0.19386973180076628
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.04403669724770641,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.07033639143730883,
        "total_reciprocal_rank": 0.20881753312945972,
        "total_hard_percision": 0.045098039215686295,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.07724301841948898,
        "total_hard_reciprocal_rank": 0.22581699346405226,
        "total_easy_percision": 0.043103448275862086,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.06426332288401251,
        "total_easy_reciprocal_rank": 0.19386973180076628
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.05122324159021404,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.07743225174417832,
        "total_reciprocal_rank": 0.20881753312945972,
        "total_hard_percision": 0.05669934640522877,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.08660838072602775,
        "total_hard_reciprocal_rank": 0.22581699346405226,
        "total_easy_percision": 0.04640804597701151,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.0693635866049659,
        "total_easy_reciprocal_rank": 0.19386973180076628
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08523008591815927,
        "total_recall": 0.24770642201834864,
        "total_f1_score": 0.10739041794087664,
        "total_reciprocal_rank": 0.1706422018348624,
        "total_hard_percision": 0.08716931216931219,
        "total_hard_recall": 0.3137254901960784,
        "total_hard_f1_score": 0.11656763715587243,
        "total_hard_reciprocal_rank": 0.2091503267973856,
        "total_easy_percision": 0.0835249042145594,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.09932079414838035,
        "total_easy_reciprocal_rank": 0.1367816091954023
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.07247706422018349,
        "total_recall": 0.12844036697247707,
        "total_f1_score": 0.08437586877953851,
        "total_reciprocal_rank": 0.09250764525993883,
        "total_hard_percision": 0.10326797385620914,
        "total_hard_recall": 0.1568627450980392,
        "total_hard_f1_score": 0.11467617349970291,
        "total_hard_reciprocal_rank": 0.11274509803921569,
        "total_easy_percision": 0.04540229885057472,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.05773249738766981,
        "total_easy_reciprocal_rank": 0.07471264367816091
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.012232415902140673,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.013761467889908258,
        "total_reciprocal_rank": 0.013761467889908258,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.005747126436781609,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.008620689655172414,
        "total_easy_reciprocal_rank": 0.008620689655172414
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550467,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.03320227173438185,
        "total_reciprocal_rank": 0.21067453563406074,
        "total_hard_percision": 0.019607843137254905,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.0373482726423903,
        "total_hard_reciprocal_rank": 0.22732528908999497,
        "total_easy_percision": 0.01551724137931035,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.029556650246305428,
        "total_easy_reciprocal_rank": 0.19603335587108403
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.017431192660550467,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.03320227173438185,
        "total_reciprocal_rank": 0.21067453563406074,
        "total_hard_percision": 0.019607843137254905,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.0373482726423903,
        "total_hard_reciprocal_rank": 0.22732528908999497,
        "total_easy_percision": 0.01551724137931035,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.029556650246305428,
        "total_easy_reciprocal_rank": 0.19603335587108403
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.030275229357798143,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.04674530362603755,
        "total_reciprocal_rank": 0.21067453563406074,
        "total_hard_percision": 0.02843137254901962,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.048552754435107405,
        "total_hard_reciprocal_rank": 0.22732528908999497,
        "total_easy_percision": 0.03189655172413794,
        "total_easy_recall": 0.3103448275862069,
        "total_easy_f1_score": 0.04515599343185552,
        "total_easy_reciprocal_rank": 0.19603335587108403
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.039949491055805114,
        "total_recall": 0.3394495412844037,
        "total_f1_score": 0.05808941313528468,
        "total_reciprocal_rank": 0.21006291483895367,
        "total_hard_percision": 0.043215771156947635,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.06346093993152818,
        "total_hard_reciprocal_rank": 0.22732528908999497,
        "total_easy_percision": 0.03707741717376606,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.053366174055829246,
        "total_easy_reciprocal_rank": 0.19488393058372772
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.08165991755441294,
        "total_recall": 0.25688073394495414,
        "total_f1_score": 0.1013294120282787,
        "total_reciprocal_rank": 0.17134791813690897,
        "total_hard_percision": 0.08346052096052098,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.1104043175842484,
        "total_hard_reciprocal_rank": 0.21065862242332828,
        "total_easy_percision": 0.08007662835249042,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.09334975369458129,
        "total_easy_reciprocal_rank": 0.1367816091954023
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.07206931702344546,
        "total_recall": 0.13761467889908258,
        "total_f1_score": 0.0837529603826079,
        "total_reciprocal_rank": 0.0932133615619854,
        "total_hard_percision": 0.10337690631808279,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.11504250823136272,
        "total_hard_reciprocal_rank": 0.11425339366515837,
        "total_easy_percision": 0.04454022988505747,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.056239737274220034,
        "total_easy_reciprocal_rank": 0.07471264367816091
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.012232415902140673,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.013761467889908258,
        "total_reciprocal_rank": 0.013761467889908258,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.005747126436781609,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.008620689655172414,
        "total_easy_reciprocal_rank": 0.008620689655172414
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.2",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.00862385321100918,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.016909516100018,
        "total_reciprocal_rank": 0.21338362229450217,
        "total_hard_percision": 0.009019607843137257,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.017685505574778923,
        "total_hard_reciprocal_rank": 0.2288317056100914,
        "total_easy_percision": 0.00827586206896552,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.01622718052738336,
        "total_easy_reciprocal_rank": 0.1997999628273462
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.3",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.00862385321100918,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.016909516100018,
        "total_reciprocal_rank": 0.21338362229450217,
        "total_hard_percision": 0.009019607843137257,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.017685505574778923,
        "total_hard_reciprocal_rank": 0.2288317056100914,
        "total_easy_percision": 0.00827586206896552,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.01622718052738336,
        "total_easy_reciprocal_rank": 0.1997999628273462
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.4",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.022432522270974607,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.032259399172513026,
        "total_reciprocal_rank": 0.21338362229450217,
        "total_hard_percision": 0.018856209150326802,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.03078815840061517,
        "total_hard_reciprocal_rank": 0.2288317056100914,
        "total_easy_percision": 0.025577211394302853,
        "total_easy_recall": 0.41379310344827586,
        "total_easy_f1_score": 0.03355307640297501,
        "total_easy_reciprocal_rank": 0.1997999628273462
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.5",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.035056993354016616,
        "total_recall": 0.4036697247706422,
        "total_f1_score": 0.04910530974956674,
        "total_reciprocal_rank": 0.21207300630498713,
        "total_hard_percision": 0.03638589732381073,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.050830356508810064,
        "total_hard_reciprocal_rank": 0.2288317056100914,
        "total_easy_percision": 0.03388847434609421,
        "total_easy_recall": 0.3620689655172414,
        "total_easy_f1_score": 0.04758845828885281,
        "total_easy_reciprocal_rank": 0.1973369086401541
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.6",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.08095486572550788,
        "total_recall": 0.27522935779816515,
        "total_f1_score": 0.10005612651168119,
        "total_reciprocal_rank": 0.17179063202639053,
        "total_hard_percision": 0.08309149456208281,
        "total_hard_recall": 0.37254901960784315,
        "total_hard_f1_score": 0.10979425775520685,
        "total_hard_reciprocal_rank": 0.21160481485378885,
        "total_easy_percision": 0.07907610588645071,
        "total_easy_recall": 0.1896551724137931,
        "total_easy_f1_score": 0.0914932869699604,
        "total_easy_reciprocal_rank": 0.1367816091954023
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.7",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.07174937253188737,
        "total_recall": 0.13761467889908258,
        "total_f1_score": 0.08316242995974593,
        "total_reciprocal_rank": 0.0932133615619854,
        "total_hard_percision": 0.10297321542996284,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.11429554277851492,
        "total_hard_reciprocal_rank": 0.11425339366515837,
        "total_easy_percision": 0.044293924466338265,
        "total_easy_recall": 0.10344827586206896,
        "total_easy_f1_score": 0.055786761791518036,
        "total_easy_reciprocal_rank": 0.07471264367816091
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-all-distilroberta-v1 0.8",
            "index_requests": [
                {
                    "index_name": "summary-all-distilroberta-v1",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.012232415902140673,
        "total_recall": 0.01834862385321101,
        "total_f1_score": 0.013761467889908258,
        "total_reciprocal_rank": 0.013761467889908258,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.005747126436781609,
        "total_easy_recall": 0.017241379310344827,
        "total_easy_f1_score": 0.008620689655172414,
        "total_easy_reciprocal_rank": 0.008620689655172414
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03211009174311928,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.23562691131498467,
        "total_hard_percision": 0.03529411764705883,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.0641711229946524,
        "total_hard_reciprocal_rank": 0.27450980392156865,
        "total_easy_percision": 0.029310344827586213,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.05329153605015673,
        "total_easy_reciprocal_rank": 0.20143678160919537
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03211009174311928,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.23562691131498467,
        "total_hard_percision": 0.03529411764705883,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.0641711229946524,
        "total_hard_reciprocal_rank": 0.27450980392156865,
        "total_easy_percision": 0.029310344827586213,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.05329153605015673,
        "total_easy_reciprocal_rank": 0.20143678160919537
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.03211009174311928,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.058381984987489546,
        "total_reciprocal_rank": 0.23562691131498467,
        "total_hard_percision": 0.03529411764705883,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.0641711229946524,
        "total_hard_reciprocal_rank": 0.27450980392156865,
        "total_easy_percision": 0.029310344827586213,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.05329153605015673,
        "total_easy_reciprocal_rank": 0.20143678160919537
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.045412844036697236,
        "total_recall": 0.3211009174311927,
        "total_f1_score": 0.07233805949402276,
        "total_reciprocal_rank": 0.23562691131498467,
        "total_hard_percision": 0.038235294117647076,
        "total_hard_recall": 0.35294117647058826,
        "total_hard_f1_score": 0.06844919786096254,
        "total_hard_reciprocal_rank": 0.27450980392156865,
        "total_easy_percision": 0.051724137931034496,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.07575757575757573,
        "total_easy_reciprocal_rank": 0.20143678160919537
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.08011504295907965,
        "total_recall": 0.29357798165137616,
        "total_f1_score": 0.10762540212081495,
        "total_reciprocal_rank": 0.22400611620795108,
        "total_hard_percision": 0.0690320572673514,
        "total_hard_recall": 0.3333333333333333,
        "total_hard_f1_score": 0.10141329258976317,
        "total_hard_reciprocal_rank": 0.2712418300653595,
        "total_easy_percision": 0.08986042692939245,
        "total_easy_recall": 0.25862068965517243,
        "total_easy_f1_score": 0.11308777429467085,
        "total_easy_reciprocal_rank": 0.1824712643678161
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.07828746177370031,
        "total_recall": 0.12844036697247707,
        "total_f1_score": 0.08612335676555861,
        "total_reciprocal_rank": 0.10856269113149845,
        "total_hard_percision": 0.10326797385620917,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.11607673372379253,
        "total_hard_reciprocal_rank": 0.1568627450980392,
        "total_easy_percision": 0.05632183908045977,
        "total_easy_recall": 0.08620689655172414,
        "total_easy_f1_score": 0.05978504254366323,
        "total_easy_reciprocal_rank": 0.0660919540229885
    },
    {
        "profile": {
            "profile_name": "BASE 10 summary-nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 10,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 10,
            "merge_method": "default"
        },
        "total_percision": 0.009174311926605505,
        "total_recall": 0.009174311926605505,
        "total_f1_score": 0.009174311926605505,
        "total_reciprocal_rank": 0.009174311926605505,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.018807339449541292,
        "total_recall": 0.3761467889908257,
        "total_f1_score": 0.035823503713411996,
        "total_reciprocal_rank": 0.2385567264085741,
        "total_hard_percision": 0.0215686274509804,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.04108309990662934,
        "total_hard_reciprocal_rank": 0.2785861713106295,
        "total_easy_percision": 0.01637931034482759,
        "total_easy_recall": 0.3275862068965517,
        "total_easy_f1_score": 0.031198686371100175,
        "total_easy_reciprocal_rank": 0.2033584214084908
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.018807339449541292,
        "total_recall": 0.3761467889908257,
        "total_f1_score": 0.035823503713411996,
        "total_reciprocal_rank": 0.2385567264085741,
        "total_hard_percision": 0.0215686274509804,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.04108309990662934,
        "total_hard_reciprocal_rank": 0.2785861713106295,
        "total_easy_percision": 0.01637931034482759,
        "total_easy_recall": 0.3275862068965517,
        "total_easy_f1_score": 0.031198686371100175,
        "total_easy_reciprocal_rank": 0.2033584214084908
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.018807339449541292,
        "total_recall": 0.3761467889908257,
        "total_f1_score": 0.035823503713411996,
        "total_reciprocal_rank": 0.2385567264085741,
        "total_hard_percision": 0.0215686274509804,
        "total_hard_recall": 0.43137254901960786,
        "total_hard_f1_score": 0.04108309990662934,
        "total_hard_reciprocal_rank": 0.2785861713106295,
        "total_easy_percision": 0.01637931034482759,
        "total_easy_recall": 0.3275862068965517,
        "total_easy_f1_score": 0.031198686371100175,
        "total_easy_reciprocal_rank": 0.2033584214084908
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.03302752293577977,
        "total_recall": 0.3669724770642202,
        "total_f1_score": 0.051288772389689784,
        "total_reciprocal_rank": 0.23807386788612114,
        "total_hard_percision": 0.02450980392156864,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.04519140989729227,
        "total_hard_reciprocal_rank": 0.2775541795665635,
        "total_easy_percision": 0.04051724137931032,
        "total_easy_recall": 0.3275862068965517,
        "total_easy_f1_score": 0.05665024630541874,
        "total_easy_reciprocal_rank": 0.2033584214084908
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.07722293801482599,
        "total_recall": 0.3302752293577982,
        "total_f1_score": 0.10297532822882889,
        "total_reciprocal_rank": 0.22591340737164015,
        "total_hard_percision": 0.06539081833199478,
        "total_hard_recall": 0.39215686274509803,
        "total_hard_f1_score": 0.09566809179812276,
        "total_hard_reciprocal_rank": 0.27428620571035434,
        "total_easy_percision": 0.08762704325317755,
        "total_easy_recall": 0.27586206896551724,
        "total_easy_f1_score": 0.10940065681444991,
        "total_easy_reciprocal_rank": 0.18337870538415005
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.07737003058103976,
        "total_recall": 0.12844036697247707,
        "total_f1_score": 0.08453473132372216,
        "total_reciprocal_rank": 0.10856269113149845,
        "total_hard_percision": 0.1022875816993464,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.11437908496732026,
        "total_hard_reciprocal_rank": 0.1568627450980392,
        "total_easy_percision": 0.055459770114942526,
        "total_easy_recall": 0.08620689655172414,
        "total_easy_f1_score": 0.05829228243021346,
        "total_easy_reciprocal_rank": 0.0660919540229885
    },
    {
        "profile": {
            "profile_name": "BASE 20 summary-nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 20,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 20,
            "merge_method": "default"
        },
        "total_percision": 0.009174311926605505,
        "total_recall": 0.009174311926605505,
        "total_f1_score": 0.009174311926605505,
        "total_reciprocal_rank": 0.009174311926605505,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.2",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.2,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.00862385321100918,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.016909516100018,
        "total_reciprocal_rank": 0.24040736321652326,
        "total_hard_percision": 0.009411764705882356,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.01845444059976931,
        "total_hard_reciprocal_rank": 0.2796746787316024,
        "total_easy_percision": 0.007931034482758623,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.015551048005409053,
        "total_easy_reciprocal_rank": 0.20587920647050525
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.3",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.3,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.00862385321100918,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.016909516100018,
        "total_reciprocal_rank": 0.24040736321652326,
        "total_hard_percision": 0.009411764705882356,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.01845444059976931,
        "total_hard_reciprocal_rank": 0.2796746787316024,
        "total_easy_percision": 0.007931034482758623,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.015551048005409053,
        "total_easy_reciprocal_rank": 0.20587920647050525
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.4",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.4,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.00862385321100918,
        "total_recall": 0.43119266055045874,
        "total_f1_score": 0.016909516100018,
        "total_reciprocal_rank": 0.24040736321652326,
        "total_hard_percision": 0.009411764705882356,
        "total_hard_recall": 0.47058823529411764,
        "total_hard_f1_score": 0.01845444059976931,
        "total_hard_reciprocal_rank": 0.2796746787316024,
        "total_easy_percision": 0.007931034482758623,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.015551048005409053,
        "total_easy_reciprocal_rank": 0.20587920647050525
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.5",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.5,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.023976864778619874,
        "total_recall": 0.42201834862385323,
        "total_f1_score": 0.03449189162293842,
        "total_reciprocal_rank": 0.2399245046940703,
        "total_hard_percision": 0.01356351236146633,
        "total_hard_recall": 0.45098039215686275,
        "total_hard_f1_score": 0.024825149083413094,
        "total_hard_reciprocal_rank": 0.27864268698753636,
        "total_easy_percision": 0.03313343328335833,
        "total_easy_recall": 0.39655172413793105,
        "total_easy_f1_score": 0.04299195833872799,
        "total_easy_reciprocal_rank": 0.20587920647050525
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.6",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.6,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.07495607861100649,
        "total_recall": 0.3486238532110092,
        "total_f1_score": 0.09879152036296106,
        "total_reciprocal_rank": 0.22657632539472386,
        "total_hard_percision": 0.0617946719694456,
        "total_hard_recall": 0.4117647058823529,
        "total_hard_f1_score": 0.08901613333202685,
        "total_hard_reciprocal_rank": 0.274918716779298,
        "total_easy_percision": 0.0865290396234135,
        "total_easy_recall": 0.29310344827586204,
        "total_easy_f1_score": 0.107387119303955,
        "total_easy_reciprocal_rank": 0.1840683605565638
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.7",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.7,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.07704696442437664,
        "total_recall": 0.12844036697247707,
        "total_f1_score": 0.08393852954025646,
        "total_reciprocal_rank": 0.10856269113149845,
        "total_hard_percision": 0.10190136660724897,
        "total_hard_recall": 0.17647058823529413,
        "total_hard_f1_score": 0.1136650738726863,
        "total_hard_reciprocal_rank": 0.1568627450980392,
        "total_easy_percision": 0.055192231470471656,
        "total_easy_recall": 0.08620689655172414,
        "total_easy_f1_score": 0.057799671592775034,
        "total_easy_reciprocal_rank": 0.0660919540229885
    },
    {
        "profile": {
            "profile_name": "BASE 50 summary-nomic-embed-text-v2 0.8",
            "index_requests": [
                {
                    "index_name": "summary-nomic-embed-text-v2",
                    "top_k": 50,
                    "confidence": 0.8,
                    "weight": 1.0
                }
            ],
            "top_k": 50,
            "merge_method": "default"
        },
        "total_percision": 0.009174311926605505,
        "total_recall": 0.009174311926605505,
        "total_f1_score": 0.009174311926605505,
        "total_reciprocal_rank": 0.009174311926605505,
        "total_hard_percision": 0.0196078431372549,
        "total_hard_recall": 0.0196078431372549,
        "total_hard_f1_score": 0.0196078431372549,
        "total_hard_reciprocal_rank": 0.0196078431372549,
        "total_easy_percision": 0.0,
        "total_easy_recall": 0.0,
        "total_easy_f1_score": 0.0,
        "total_easy_reciprocal_rank": 0.0
    }
]